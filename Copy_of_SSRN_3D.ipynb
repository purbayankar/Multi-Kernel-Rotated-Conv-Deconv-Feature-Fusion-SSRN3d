{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SSRN-3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purbayankar/Multi-Kernel-Rotated-Conv-Deconv-Feature-Fusion-SSRN3d/blob/main/Copy_of_SSRN_3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZBwiH5Zl8a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46aa4791-5021-4e26-8e4f-b84ba2b0350d"
      },
      "source": [
        "!pip install spectral==0.20\n",
        "!mkdir /content/classification_maps/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spectral==0.20 in /usr/local/lib/python3.6/dist-packages (0.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectral==0.20) (1.19.5)\n",
            "mkdir: cannot create directory ‘/content/classification_maps/’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz_W1NnQNhyG"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from operator import truediv\n",
        "\n",
        "def evaluate_accuracy(data_iter, net, loss, device):\n",
        "    acc_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            test_l_sum, test_num = 0, 0\n",
        "            #X = X.permute(0, 3, 1, 2)\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            net.eval() \n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y.long())\n",
        "            acc_sum += (y_hat.argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
        "            test_l_sum += l\n",
        "            test_num += 1\n",
        "            net.train() \n",
        "            n += y.shape[0]\n",
        "    return [acc_sum / n, test_l_sum] # / test_num]\n",
        "\n",
        "\n",
        "def aa_and_each_accuracy(confusion_matrix):\n",
        "    list_diag = np.diag(confusion_matrix)\n",
        "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
        "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
        "    average_acc = np.mean(each_acc)\n",
        "    return each_acc, average_acc\n",
        "\n",
        "\n",
        "\n",
        "def record_output(oa_ae, aa_ae, kappa_ae, element_acc_ae, training_time_ae, testing_time_ae, confusion_matrix, path):\n",
        "    f = open(path, 'a')\n",
        "    sentence0 = 'OAs for each iteration are:' + str(oa_ae) + '\\n'\n",
        "    f.write(sentence0)\n",
        "    sentence1 = 'AAs for each iteration are:' + str(aa_ae) + '\\n'\n",
        "    f.write(sentence1)\n",
        "    sentence2 = 'KAPPAs for each iteration are:' + str(kappa_ae) + '\\n' + '\\n'\n",
        "    f.write(sentence2)\n",
        "    sentence3 = 'mean_OA ± std_OA is: ' + str(np.mean(oa_ae)) + ' ± ' + str(np.std(oa_ae)) + '\\n'\n",
        "    f.write(sentence3)\n",
        "    sentence4 = 'mean_AA ± std_AA is: ' + str(np.mean(aa_ae)) + ' ± ' + str(np.std(aa_ae)) + '\\n'\n",
        "    f.write(sentence4)\n",
        "    sentence5 = 'mean_KAPPA ± std_KAPPA is: ' + str(np.mean(kappa_ae)) + ' ± ' + str(np.std(kappa_ae)) + '\\n' + '\\n'\n",
        "    f.write(sentence5)\n",
        "    sentence6 = 'Total average Training time is: ' + str(np.sum(training_time_ae)) + '\\n'\n",
        "    f.write(sentence6)\n",
        "    sentence7 = 'Total average Testing time is: ' + str(np.sum(testing_time_ae)) + '\\n' + '\\n'\n",
        "    f.write(sentence7)\n",
        "    element_mean = np.mean(element_acc_ae, axis=0)\n",
        "    element_std = np.std(element_acc_ae, axis=0)\n",
        "    sentence8 = \"Mean of all elements in confusion matrix: \" + str(element_mean) + '\\n'\n",
        "    f.write(sentence8)\n",
        "    sentence9 = \"Standard deviation of all elements in confusion matrix: \" + str(element_std) + '\\n'\n",
        "    f.write(sentence9)\n",
        "    sentence10 = \"The diagonal Confusion matrix: \" + '\\n' + str(confusion_matrix) + '\\n'\n",
        "    f.write(sentence10)\n",
        "    f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLhNOo-GNgia"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.utils.data as Data\n",
        "\n",
        "def index_assignment(index, row, col, pad_length):\n",
        "    new_assign = {}\n",
        "    for counter, value in enumerate(index):\n",
        "        assign_0 = value // col + pad_length\n",
        "        assign_1 = value % col + pad_length\n",
        "        new_assign[counter] = [assign_0, assign_1]\n",
        "    return new_assign\n",
        "\n",
        "def select_patch(matrix, pos_row, pos_col, ex_len):\n",
        "    selected_rows = matrix[range(pos_row-ex_len, pos_row+ex_len+1)]\n",
        "    selected_patch = selected_rows[:, range(pos_col-ex_len, pos_col+ex_len+1)]\n",
        "    return selected_patch\n",
        "\n",
        "\n",
        "def select_small_cubic(data_size, data_indices, whole_data, patch_length, padded_data, dimension):\n",
        "    small_cubic_data = np.zeros((data_size, 2 * patch_length + 1, 2 * patch_length + 1, dimension))\n",
        "    data_assign = index_assignment(data_indices, whole_data.shape[0], whole_data.shape[1], patch_length)\n",
        "    for i in range(len(data_assign)):\n",
        "        small_cubic_data[i] = select_patch(padded_data, data_assign[i][0], data_assign[i][1], patch_length)\n",
        "    return small_cubic_data\n",
        "\n",
        "\n",
        "def generate_iter(TRAIN_SIZE, train_indices, TEST_SIZE, test_indices, TOTAL_SIZE, total_indices, VAL_SIZE,\n",
        "                  whole_data, PATCH_LENGTH, padded_data, INPUT_DIMENSION, batch_size, gt):\n",
        "    gt_all = gt[total_indices] - 1\n",
        "    y_train = gt[train_indices] - 1\n",
        "    y_test = gt[test_indices] - 1\n",
        "\n",
        "    all_data =  select_small_cubic(TOTAL_SIZE, total_indices, whole_data,\n",
        "                                                      PATCH_LENGTH, padded_data, INPUT_DIMENSION)\n",
        "\n",
        "    train_data = select_small_cubic(TRAIN_SIZE, train_indices, whole_data,\n",
        "                                                        PATCH_LENGTH, padded_data, INPUT_DIMENSION)\n",
        "    print(train_data.shape)\n",
        "    test_data =  select_small_cubic(TEST_SIZE, test_indices, whole_data,\n",
        "                                                       PATCH_LENGTH, padded_data, INPUT_DIMENSION)\n",
        "    x_train = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2], INPUT_DIMENSION)\n",
        "    x_test_all = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2], INPUT_DIMENSION)\n",
        "\n",
        "    x_val = x_test_all[-VAL_SIZE:]\n",
        "    y_val = y_test[-VAL_SIZE:]\n",
        "\n",
        "    x_test = x_test_all[:-VAL_SIZE]\n",
        "    y_test = y_test[:-VAL_SIZE]\n",
        "    \n",
        "    x1_tensor_train = torch.from_numpy(x_train).type(torch.FloatTensor).unsqueeze(1)\n",
        "    y1_tensor_train = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
        "    torch_dataset_train = Data.TensorDataset(x1_tensor_train, y1_tensor_train)\n",
        "\n",
        "    x1_tensor_valida = torch.from_numpy(x_val).type(torch.FloatTensor).unsqueeze(1)\n",
        "    y1_tensor_valida = torch.from_numpy(y_val).type(torch.FloatTensor)\n",
        "    torch_dataset_valida = Data.TensorDataset(x1_tensor_valida, y1_tensor_valida)\n",
        "\n",
        "    x1_tensor_test = torch.from_numpy(x_test).type(torch.FloatTensor).unsqueeze(1)\n",
        "    y1_tensor_test = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
        "    torch_dataset_test = Data.TensorDataset(x1_tensor_test,y1_tensor_test)\n",
        "\n",
        "    all_data.reshape(all_data.shape[0], all_data.shape[1], all_data.shape[2], INPUT_DIMENSION)\n",
        "    all_tensor_data = torch.from_numpy(all_data).type(torch.FloatTensor).unsqueeze(1)\n",
        "    all_tensor_data_label = torch.from_numpy(gt_all).type(torch.FloatTensor)\n",
        "    torch_dataset_all = Data.TensorDataset(all_tensor_data, all_tensor_data_label)\n",
        "\n",
        "\n",
        "    train_iter = Data.DataLoader(\n",
        "        dataset=torch_dataset_train,  # torch TensorDataset format\n",
        "        batch_size=batch_size,  # mini batch size\n",
        "        shuffle=True,  \n",
        "        num_workers=0, \n",
        "    )\n",
        "    valiada_iter = Data.DataLoader(\n",
        "        dataset=torch_dataset_valida,  # torch TensorDataset format\n",
        "        batch_size=batch_size,  # mini batch size\n",
        "        shuffle=True,  \n",
        "        num_workers=0, \n",
        "    )\n",
        "    test_iter = Data.DataLoader(\n",
        "        dataset=torch_dataset_test,  # torch TensorDataset format\n",
        "        batch_size=batch_size,  # mini batch size\n",
        "        shuffle=False, \n",
        "        num_workers=0, \n",
        "    )\n",
        "    all_iter = Data.DataLoader(\n",
        "        dataset=torch_dataset_all,  # torch TensorDataset format\n",
        "        batch_size=batch_size,  # mini batch size\n",
        "        shuffle=False, \n",
        "        num_workers=0, \n",
        "    )\n",
        "    return train_iter, valiada_iter, test_iter, all_iter #, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Ies1WPNbuF"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics, preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "from operator import truediv\n",
        "from plotly.offline import init_notebook_mode\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import spectral\n",
        "import torch\n",
        "import cv2\n",
        "from operator import truediv\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "def sampling(proportion, ground_truth):\n",
        "    train = {}\n",
        "    test = {}\n",
        "    labels_loc = {}\n",
        "    m = max(ground_truth)\n",
        "    for i in range(m):\n",
        "        indexes = [j for j, x in enumerate(ground_truth.ravel().tolist()) if x == i + 1]\n",
        "        np.random.shuffle(indexes)\n",
        "        labels_loc[i] = indexes\n",
        "        if proportion != 1:\n",
        "            nb_val = max(int((1 - proportion) * len(indexes)), 3)\n",
        "        else:\n",
        "            nb_val = 0\n",
        "        train[i] = indexes[:nb_val]\n",
        "        test[i] = indexes[nb_val:]\n",
        "    train_indexes = []\n",
        "    test_indexes = []\n",
        "    for i in range(m):\n",
        "        train_indexes += train[i]\n",
        "        test_indexes += test[i]\n",
        "    np.random.shuffle(train_indexes)\n",
        "    np.random.shuffle(test_indexes)\n",
        "    return train_indexes, test_indexes\n",
        "\n",
        "\n",
        "\n",
        "def set_figsize(figsize=(3.5, 2.5)):\n",
        "    display.set_matplotlib_formats('svg')\n",
        "    plt.rcParams['figure.figsize'] = figsize\n",
        "\n",
        "\n",
        "def classification_map(map, ground_truth, dpi, save_path):\n",
        "    fig = plt.figure(frameon=False)\n",
        "    fig.set_size_inches(ground_truth.shape[1] * 2.0 / dpi, ground_truth.shape[0] * 2.0 / dpi)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.yaxis.set_visible(False)\n",
        "    fig.add_axes(ax)\n",
        "    ax.imshow(map)\n",
        "    fig.savefig(save_path, dpi=dpi)\n",
        "    return 0\n",
        "\n",
        "\n",
        "def list_to_colormap(x_list):\n",
        "    y = np.zeros((x_list.shape[0], 3))\n",
        "    for index, item in enumerate(x_list):\n",
        "        if item == 0:\n",
        "            y[index] = np.array([255, 0, 0]) / 255.\n",
        "        if item == 1:\n",
        "            y[index] = np.array([0, 255, 0]) / 255.\n",
        "        if item == 2:\n",
        "            y[index] = np.array([0, 0, 255]) / 255.\n",
        "        if item == 3:\n",
        "            y[index] = np.array([255, 255, 0]) / 255.\n",
        "        if item == 4:\n",
        "            y[index] = np.array([0, 255, 255]) / 255.\n",
        "        if item == 5:\n",
        "            y[index] = np.array([255, 0, 255]) / 255.\n",
        "        if item == 6:\n",
        "            y[index] = np.array([192, 192, 192]) / 255.\n",
        "        if item == 7:\n",
        "            y[index] = np.array([128, 128, 128]) / 255.\n",
        "        if item == 8:\n",
        "            y[index] = np.array([128, 0, 0]) / 255.\n",
        "        if item == 9:\n",
        "            y[index] = np.array([128, 128, 0]) / 255.\n",
        "        if item == 10:\n",
        "            y[index] = np.array([0, 128, 0]) / 255.\n",
        "        if item == 11:\n",
        "            y[index] = np.array([128, 0, 128]) / 255.\n",
        "        if item == 12:\n",
        "            y[index] = np.array([0, 128, 128]) / 255.\n",
        "        if item == 13:\n",
        "            y[index] = np.array([0, 0, 128]) / 255.\n",
        "        if item == 14:\n",
        "            y[index] = np.array([255, 165, 0]) / 255.\n",
        "        if item == 15:\n",
        "            y[index] = np.array([255, 215, 0]) / 255.\n",
        "        if item == 16:\n",
        "            y[index] = np.array([0, 0, 0]) / 255.\n",
        "        if item == 17:\n",
        "            y[index] = np.array([215, 255, 0]) / 255.\n",
        "        if item == 18:\n",
        "            y[index] = np.array([0, 255, 215]) / 255.\n",
        "        if item == -1:\n",
        "            y[index] = np.array([0, 0, 0]) / 255.\n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "def generate_png(all_iter, net, gt_hsi, Dataset, device, total_indices):\n",
        "    pred_test = []\n",
        "    for X, y in all_iter:\n",
        "        #X = X.permute(0, 3, 1, 2)\n",
        "        X = X.to(device)\n",
        "        net.eval() \n",
        "        pred_test.extend(net(X).cpu().argmax(axis=1).detach().numpy())\n",
        "    gt = gt_hsi.flatten()\n",
        "    x_label = np.zeros(gt.shape)\n",
        "    for i in range(len(gt)):\n",
        "        if gt[i] == 0:\n",
        "            gt[i] = 17\n",
        "            x_label[i] = 16\n",
        "    gt = gt[:] - 1\n",
        "    x_label[total_indices] = pred_test\n",
        "    x = np.ravel(x_label)\n",
        "    y_list = list_to_colormap(x)\n",
        "    y_gt = list_to_colormap(gt)\n",
        "    y_re = np.reshape(y_list, (gt_hsi.shape[0], gt_hsi.shape[1], 3))\n",
        "    gt_re = np.reshape(y_gt, (gt_hsi.shape[0], gt_hsi.shape[1], 3))\n",
        "    path = '/content/' \n",
        "    classification_map(y_re, gt_hsi, 300,\n",
        "                       path + '/classification_maps/' + Dataset + '_'  +  '.png')\n",
        "    classification_map(gt_re, gt_hsi, 300,\n",
        "                       path + '/classification_maps/' + Dataset + '_gt.png')\n",
        "    print('------Get classification maps successful-------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd6CFjpCPs0-"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzId60D8SqZv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "cb184baf-5763-41ce-c315-1b6d61ae3775"
      },
      "source": [
        "from sklearn import metrics, preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import spectral\n",
        "import cv2\n",
        "from operator import truediv\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9mKmz0-LGsX"
      },
      "source": [
        "# Downloading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVBWDnt60jZf"
      },
      "source": [
        "if not (os.path.isfile('/content/Indian_pines_corrected.mat')):\n",
        "  !wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
        "if not (os.path.isfile('/content/Indian_pines_gt.mat')):\n",
        "  !wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
        "\n",
        "if not (os.path.isfile('/content/Salinas_corrected.mat')):\n",
        "  !wget https://github.com/gokriznastic/HybridSN/raw/master/data/Salinas_corrected.mat\n",
        "if not (os.path.isfile('/content/Salinas_gt.mat')):\n",
        "  !wget https://github.com/gokriznastic/HybridSN/raw/master/data/Salinas_gt.mat\n",
        "\n",
        "#if not (os.path.isfile('/content/PaviaU.mat')):\n",
        "#  !wget http://www.ehu.eus/ccwintco/uploads/e/ee/PaviaU.mat\n",
        "#if not (os.path.isfile('/content/PaviaU_gt.mat')):\n",
        "#  !wget http://www.ehu.eus/ccwintco/uploads/5/50/PaviaU_gt.mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxBquyfBSqZ9"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBa0-ryLOUj3"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# for Monte Carlo runs\n",
        "seeds = [1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341]\n",
        "ensemble = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4Xf3aydOUgK"
      },
      "source": [
        "global Dataset  # UP,IN,SV\n",
        "dataset = 'IN' #input('Please input the name of Dataset(IN, UP, SV):')\n",
        "Dataset = dataset.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfP7l-KSPywy"
      },
      "source": [
        "# import Utils,geniter,record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAMxIwonMYIC"
      },
      "source": [
        "def load_dataset(Dataset):\n",
        "    if Dataset == 'IN':\n",
        "        mat_data = sio.loadmat('/content/Indian_pines_corrected.mat')\n",
        "        mat_gt = sio.loadmat('/content/Indian_pines_gt.mat')\n",
        "        data_hsi = mat_data['indian_pines_corrected']\n",
        "        gt_hsi = mat_gt['indian_pines_gt']\n",
        "        K = 200\n",
        "        TOTAL_SIZE = 10249\n",
        "        VALIDATION_SPLIT = 0.90\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "    if Dataset == 'UP':\n",
        "        uPavia = sio.loadmat('/content/PaviaU.mat')\n",
        "        gt_uPavia = sio.loadmat('/content/PaviaU_gt.mat')\n",
        "        data_hsi = uPavia['paviaU']\n",
        "        gt_hsi = gt_uPavia['paviaU_gt']\n",
        "        K = 15\n",
        "        TOTAL_SIZE = 42776\n",
        "        VALIDATION_SPLIT = 0.90\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "    if Dataset == 'SV':\n",
        "        SV = sio.loadmat('/content/Salinas_corrected.mat')\n",
        "        gt_SV = sio.loadmat('/content/Salinas_gt.mat')\n",
        "        data_hsi = SV['salinas_corrected']\n",
        "        gt_hsi = gt_SV['salinas_gt']\n",
        "        K = 15\n",
        "        TOTAL_SIZE = 54129\n",
        "        VALIDATION_SPLIT = 0.90\n",
        "        TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
        "\n",
        "\n",
        "    # shapeor=data_hsi.shape\n",
        "    # data_hsi = data_hsi.reshape(-1,data_hsi.shape[-1])\n",
        "    # data_hsi = PCA(n_components=K).fit_transform(data_hsi)\n",
        "    # shapeor = np.array(shapeor)\n",
        "    # shapeor[-1] = K\n",
        "    # data_hsi = data_hsi.reshape(shapeor)    \n",
        "\n",
        "\n",
        "    return data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN4NquhyK45v"
      },
      "source": [
        "# Pytorch Data Loader Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSn0wZkRNKSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a9632fd-b756-402c-a31a-56af96605f10"
      },
      "source": [
        "import math\n",
        "data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE,VALIDATION_SPLIT = load_dataset(Dataset)\n",
        "print(data_hsi.shape)\n",
        "image_x, image_y, BAND = data_hsi.shape\n",
        "data = data_hsi.reshape(np.prod(data_hsi.shape[:2]), np.prod(data_hsi.shape[2:]))\n",
        "gt = gt_hsi.reshape(np.prod(gt_hsi.shape[:2]),)\n",
        "CLASSES_NUM = max(gt)\n",
        "print('The class numbers of the HSI data is:', CLASSES_NUM)\n",
        "\n",
        "print('-----Importing Setting Parameters-----')\n",
        "ITER = 3\n",
        "PATCH_LENGTH = 4\n",
        "lr, num_epochs, batch_size = 0.001, 100, 32\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "img_rows = 2*PATCH_LENGTH+1\n",
        "img_cols = 2*PATCH_LENGTH+1\n",
        "img_channels = data_hsi.shape[2]\n",
        "INPUT_DIMENSION = data_hsi.shape[2]\n",
        "ALL_SIZE = data_hsi.shape[0] * data_hsi.shape[1]\n",
        "VAL_SIZE = int(TRAIN_SIZE)\n",
        "TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
        "\n",
        "\n",
        "KAPPA = []\n",
        "OA = []\n",
        "AA = []\n",
        "TRAINING_TIME = []\n",
        "TESTING_TIME = []\n",
        "ELEMENT_ACC = np.zeros((ITER, CLASSES_NUM))\n",
        "\n",
        "data = preprocessing.scale(data)\n",
        "data_ = data.reshape(data_hsi.shape[0], data_hsi.shape[1], data_hsi.shape[2])\n",
        "whole_data = data_\n",
        "padded_data = np.lib.pad(whole_data, ((PATCH_LENGTH, PATCH_LENGTH), (PATCH_LENGTH, PATCH_LENGTH), (0, 0)),\n",
        "                         'constant', constant_values=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(145, 145, 200)\n",
            "The class numbers of the HSI data is: 16\n",
            "-----Importing Setting Parameters-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEJHCEg7g7pO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJPvghYskVX_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from torch.nn.modules import conv\n",
        "from torch.nn.modules.utils import _pair\n",
        "import math\n",
        "\n",
        "#iteratively solve for inverse sqrt of a matrix\n",
        "def isqrt_newton_schulz_autograd(A, numIters):\n",
        "    dim = A.shape[0]\n",
        "    normA=A.norm()\n",
        "    Y = A.div(normA)\n",
        "    I = torch.eye(dim,dtype=A.dtype,device=A.device)\n",
        "    Z = torch.eye(dim,dtype=A.dtype,device=A.device)\n",
        "\n",
        "    for i in range(numIters):\n",
        "        T = 0.5*(3.0*I - Z@Y)\n",
        "        Y = Y@T\n",
        "        Z = T@Z\n",
        "    #A_sqrt = Y*torch.sqrt(normA)\n",
        "    A_isqrt = Z / torch.sqrt(normA)\n",
        "    return A_isqrt\n",
        "\n",
        "def isqrt_newton_schulz_autograd_batch(A, numIters):\n",
        "    batchSize,dim,_ = A.shape\n",
        "    normA=A.view(batchSize, -1).norm(2, 1).view(batchSize, 1, 1)\n",
        "    Y = A.div(normA)\n",
        "    I = torch.eye(dim,dtype=A.dtype,device=A.device).unsqueeze(0).expand_as(A)\n",
        "    Z = torch.eye(dim,dtype=A.dtype,device=A.device).unsqueeze(0).expand_as(A)\n",
        "\n",
        "    for i in range(numIters):\n",
        "        T = 0.5*(3.0*I - Z.bmm(Y))\n",
        "        Y = Y.bmm(T)\n",
        "        Z = T.bmm(Z)\n",
        "    #A_sqrt = Y*torch.sqrt(normA)\n",
        "    A_isqrt = Z / torch.sqrt(normA)\n",
        "\n",
        "    return A_isqrt\n",
        "\n",
        "\n",
        "\n",
        "#deconvolve channels\n",
        "class ChannelDeconv(nn.Module):\n",
        "    def __init__(self,  block, eps=1e-2,n_iter=5,momentum=0.1,sampling_stride=3):\n",
        "        super(ChannelDeconv, self).__init__()\n",
        "\n",
        "        self.eps = eps\n",
        "        self.n_iter=n_iter\n",
        "        self.momentum=momentum\n",
        "        self.block = block\n",
        "\n",
        "        self.register_buffer('running_mean1', torch.zeros(block, 1))\n",
        "        #self.register_buffer('running_cov', torch.eye(block))\n",
        "        self.register_buffer('running_deconv', torch.eye(block))\n",
        "        self.register_buffer('running_mean2', torch.zeros(1, 1))\n",
        "        self.register_buffer('running_var', torch.ones(1, 1))\n",
        "        self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
        "        self.sampling_stride=sampling_stride\n",
        "    def forward(self, x):\n",
        "        x_shape = x.shape\n",
        "        if len(x.shape)==2:\n",
        "            x=x.view(x.shape[0],x.shape[1],1,1)\n",
        "        if len(x.shape)==3:\n",
        "            print('Error! Unsupprted tensor shape.')\n",
        "\n",
        "        N, C, H, W = x.size()\n",
        "        B = self.block\n",
        "\n",
        "        #take the first c channels out for deconv\n",
        "        c=int(C/B)*B\n",
        "        if c==0:\n",
        "            print('Error! block should be set smaller.')\n",
        "\n",
        "        #step 1. remove mean\n",
        "        if c!=C:\n",
        "            x1=x[:,:c].permute(1,0,2,3).contiguous().view(B,-1)\n",
        "        else:\n",
        "            x1=x.permute(1,0,2,3).contiguous().view(B,-1)\n",
        "\n",
        "        if self.sampling_stride > 1 and H >= self.sampling_stride and W >= self.sampling_stride:\n",
        "            x1_s = x1[:,::self.sampling_stride**2]\n",
        "        else:\n",
        "            x1_s=x1\n",
        "\n",
        "        mean1 = x1_s.mean(-1, keepdim=True)\n",
        "\n",
        "        if self.num_batches_tracked==0:\n",
        "            self.running_mean1.copy_(mean1.detach())\n",
        "        if self.training:\n",
        "            self.running_mean1.mul_(1-self.momentum)\n",
        "            self.running_mean1.add_(mean1.detach()*self.momentum)\n",
        "        else:\n",
        "            mean1 = self.running_mean1\n",
        "\n",
        "        x1=x1-mean1\n",
        "\n",
        "        #step 2. calculate deconv@x1 = cov^(-0.5)@x1\n",
        "        if self.training:\n",
        "            cov = x1_s @ x1_s.t() / x1_s.shape[1] + self.eps * torch.eye(B, dtype=x.dtype, device=x.device)\n",
        "            deconv = isqrt_newton_schulz_autograd(cov, self.n_iter)\n",
        "\n",
        "        if self.num_batches_tracked==0:\n",
        "            #self.running_cov.copy_(cov.detach())\n",
        "            self.running_deconv.copy_(deconv.detach())\n",
        "\n",
        "        if self.training:\n",
        "            #self.running_cov.mul_(1-self.momentum)\n",
        "            #self.running_cov.add_(cov.detach()*self.momentum)\n",
        "            self.running_deconv.mul_(1 - self.momentum)\n",
        "            self.running_deconv.add_(deconv.detach() * self.momentum)\n",
        "        else:\n",
        "            # cov = self.running_cov\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        x1 =deconv@x1\n",
        "\n",
        "        #reshape to N,c,J,W\n",
        "        x1 = x1.view(c, N, H, W).contiguous().permute(1,0,2,3)\n",
        "\n",
        "        # normalize the remaining channels\n",
        "        if c!=C:\n",
        "            x_tmp=x[:, c:].view(N,-1)\n",
        "            if self.sampling_stride > 1 and H>=self.sampling_stride and W>=self.sampling_stride:\n",
        "                x_s = x_tmp[:, ::self.sampling_stride ** 2]\n",
        "            else:\n",
        "                x_s = x_tmp\n",
        "\n",
        "            mean2=x_s.mean()\n",
        "            var=x_s.var()\n",
        "\n",
        "            if self.num_batches_tracked == 0:\n",
        "                self.running_mean2.copy_(mean2.detach())\n",
        "                self.running_var.copy_(var.detach())\n",
        "\n",
        "            if self.training:\n",
        "                self.running_mean2.mul_(1 - self.momentum)\n",
        "                self.running_mean2.add_(mean2.detach() * self.momentum)\n",
        "                self.running_var.mul_(1 - self.momentum)\n",
        "                self.running_var.add_(var.detach() * self.momentum)\n",
        "            else:\n",
        "                mean2 = self.running_mean2\n",
        "                var = self.running_var\n",
        "\n",
        "            x_tmp = (x[:, c:] - mean2) / (var + self.eps).sqrt()\n",
        "            x1 = torch.cat([x1, x_tmp], dim=1)\n",
        "\n",
        "\n",
        "        if self.training:\n",
        "            self.num_batches_tracked.add_(1)\n",
        "\n",
        "        if len(x_shape)==2:\n",
        "            x1=x1.view(x_shape)\n",
        "        return x1\n",
        "\n",
        "#An alternative implementation\n",
        "class Delinear(nn.Module):\n",
        "    __constants__ = ['bias', 'in_features', 'out_features']\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True, eps=1e-5, n_iter=5, momentum=0.1, block=512):\n",
        "        super(Delinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "\n",
        "\n",
        "        if block > in_features:\n",
        "            block = in_features\n",
        "        else:\n",
        "            if in_features%block!=0:\n",
        "                block=math.gcd(block,in_features)\n",
        "                print('block size set to:', block)\n",
        "        self.block = block\n",
        "        self.momentum = momentum\n",
        "        self.n_iter = n_iter\n",
        "        self.eps = eps\n",
        "        self.register_buffer('running_mean', torch.zeros(self.block))\n",
        "        self.register_buffer('running_deconv', torch.eye(self.block))\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        if self.training:\n",
        "\n",
        "            # 1. reshape\n",
        "            X=input.view(-1, self.block)\n",
        "\n",
        "            # 2. subtract mean\n",
        "            X_mean = X.mean(0)\n",
        "            X = X - X_mean.unsqueeze(0)\n",
        "            self.running_mean.mul_(1 - self.momentum)\n",
        "            self.running_mean.add_(X_mean.detach() * self.momentum)\n",
        "\n",
        "            # 3. calculate COV, COV^(-0.5), then deconv\n",
        "            # Cov = X.t() @ X / X.shape[0] + self.eps * torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "            Id = torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "            Cov = torch.addmm(self.eps, Id, 1. / X.shape[0], X.t(), X)\n",
        "            deconv = isqrt_newton_schulz_autograd(Cov, self.n_iter)\n",
        "            # track stats for evaluation\n",
        "            self.running_deconv.mul_(1 - self.momentum)\n",
        "            self.running_deconv.add_(deconv.detach() * self.momentum)\n",
        "\n",
        "        else:\n",
        "            X_mean = self.running_mean\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        w = self.weight.view(-1, self.block) @ deconv\n",
        "        b = self.bias\n",
        "        if self.bias is not None:\n",
        "            b = b - (w @ (X_mean.unsqueeze(1))).view(self.weight.shape[0], -1).sum(1)\n",
        "        w = w.view(self.weight.shape)\n",
        "        return F.linear(input, w, b)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return 'in_features={}, out_features={}, bias={}'.format(\n",
        "            self.in_features, self.out_features, self.bias is not None\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class FastDeconv(conv._ConvNd):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,groups=1,bias=True, eps=1e-5, n_iter=5, momentum=0.1, block=64, sampling_stride=3,freeze=False,freeze_iter=100):\n",
        "        self.momentum = momentum\n",
        "        self.n_iter = n_iter\n",
        "        self.eps = eps\n",
        "        self.counter=0\n",
        "        self.track_running_stats=True\n",
        "        super(FastDeconv, self).__init__(\n",
        "            in_channels, out_channels,  _pair(kernel_size), _pair(stride), _pair(padding), _pair(dilation),\n",
        "            False, _pair(0), groups, bias, padding_mode='zeros')\n",
        "\n",
        "        if block > in_channels:\n",
        "            block = in_channels\n",
        "        else:\n",
        "            if in_channels%block!=0:\n",
        "                block=math.gcd(block,in_channels)\n",
        "\n",
        "        if groups>1:\n",
        "            #grouped conv\n",
        "            block=in_channels//groups\n",
        "\n",
        "        self.block=block\n",
        "\n",
        "        self.num_features = kernel_size**2 *block\n",
        "        if groups==1:\n",
        "            self.register_buffer('running_mean', torch.zeros(self.num_features))\n",
        "            self.register_buffer('running_deconv', torch.eye(self.num_features))\n",
        "        else:\n",
        "            self.register_buffer('running_mean', torch.zeros(kernel_size ** 2 * in_channels))\n",
        "            self.register_buffer('running_deconv', torch.eye(self.num_features).repeat(in_channels // block, 1, 1))\n",
        "\n",
        "        self.sampling_stride=sampling_stride*stride\n",
        "        self.counter=0\n",
        "        self.freeze_iter=freeze_iter\n",
        "        self.freeze=freeze\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        B = self.block\n",
        "        frozen=self.freeze and (self.counter>self.freeze_iter)\n",
        "        if self.training and self.track_running_stats:\n",
        "            self.counter+=1\n",
        "            self.counter %= (self.freeze_iter * 10)\n",
        "\n",
        "        if self.training and (not frozen):\n",
        "\n",
        "            # 1. im2col: N x cols x pixels -> N*pixles x cols\n",
        "            if self.kernel_size[0]>1:\n",
        "                X = torch.nn.functional.unfold(x, self.kernel_size,self.dilation,self.padding,self.sampling_stride).transpose(1, 2).contiguous()\n",
        "            else:\n",
        "                #channel wise\n",
        "                X = x.permute(0, 2, 3, 1).contiguous().view(-1, C)[::self.sampling_stride**2,:]\n",
        "\n",
        "            if self.groups==1:\n",
        "                # (C//B*N*pixels,k*k*B)\n",
        "                X = X.view(-1, self.num_features, C // B).transpose(1, 2).contiguous().view(-1, self.num_features)\n",
        "            else:\n",
        "                X=X.view(-1,X.shape[-1])\n",
        "\n",
        "            # 2. subtract mean\n",
        "            X_mean = X.mean(0)\n",
        "            X = X - X_mean.unsqueeze(0)\n",
        "\n",
        "            # 3. calculate COV, COV^(-0.5), then deconv\n",
        "            if self.groups==1:\n",
        "                #Cov = X.t() @ X / X.shape[0] + self.eps * torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "                Id=torch.eye(X.shape[1], dtype=X.dtype, device=X.device)\n",
        "                Cov = torch.addmm(self.eps, Id, 1. / X.shape[0], X.t(), X)\n",
        "                deconv = isqrt_newton_schulz_autograd(Cov, self.n_iter)\n",
        "            else:\n",
        "                X = X.view(-1, self.groups, self.num_features).transpose(0, 1)\n",
        "                Id = torch.eye(self.num_features, dtype=X.dtype, device=X.device).expand(self.groups, self.num_features, self.num_features)\n",
        "                Cov = torch.baddbmm(self.eps, Id, 1. / X.shape[1], X.transpose(1, 2), X)\n",
        "\n",
        "                deconv = isqrt_newton_schulz_autograd_batch(Cov, self.n_iter)\n",
        "\n",
        "            if self.track_running_stats:\n",
        "                self.running_mean.mul_(1 - self.momentum)\n",
        "                self.running_mean.add_(X_mean.detach() * self.momentum)\n",
        "                # track stats for evaluation\n",
        "                self.running_deconv.mul_(1 - self.momentum)\n",
        "                self.running_deconv.add_(deconv.detach() * self.momentum)\n",
        "\n",
        "        else:\n",
        "            X_mean = self.running_mean\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        #4. X * deconv * conv = X * (deconv * conv)\n",
        "        if self.groups==1:\n",
        "            w = self.weight.view(-1, self.num_features, C // B).transpose(1, 2).contiguous().view(-1,self.num_features) @ deconv\n",
        "            b = self.bias - (w @ (X_mean.unsqueeze(1))).view(self.weight.shape[0], -1).sum(1)\n",
        "            w = w.view(-1, C // B, self.num_features).transpose(1, 2).contiguous()\n",
        "        else:\n",
        "            w = self.weight.view(C//B, -1,self.num_features)@deconv\n",
        "            b = self.bias - (w @ (X_mean.view( -1,self.num_features,1))).view(self.bias.shape)\n",
        "\n",
        "        w = w.view(self.weight.shape)\n",
        "        x= F.conv2d(x, w, b, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc9cZaVfQVG-"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdYF8DLbg7Hx"
      },
      "source": [
        "class Residual(nn.Module):  # pytorch\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding, use_1x1conv=False, stride=1):\n",
        "        super(Residual, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels,\n",
        "                      kernel_size=kernel_size, padding=padding, stride=stride),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels,\n",
        "                               kernel_size=kernel_size, padding=padding,stride=stride)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
        "        else:\n",
        "            self.conv3 = None\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X)\n",
        "        return F.relu(Y + X)\n",
        "\n",
        "class SSRN_network(nn.Module):\n",
        "    def __init__(self, band, classes):\n",
        "        super(SSRN_network, self).__init__()\n",
        "        # self.name = 'SSRN'\n",
        "        # self.classes = classes\n",
        "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=24,\n",
        "                                kernel_size=(1, 1, 7), stride=(1, 1, 2))\n",
        "        self.batch_norm1 = nn.Sequential(\n",
        "            nn.BatchNorm3d(24, eps=0.001, momentum=0.1, affine=True),  # 0.1\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.res_net1 = Residual(24, 24, (1, 1, 7), (0, 0, 3))\n",
        "        self.res_net2 = Residual(24, 24, (1, 1, 7), (0, 0, 3))\n",
        "        self.res_net3 = Residual(24, 24, (3, 3, 1), (1, 1, 0))\n",
        "        self.res_net4 = Residual(24, 24, (3, 3, 1), (1, 1, 0))\n",
        "\n",
        "        kernel_3d = math.ceil((band - 6) / 2)\n",
        "\n",
        "        self.conv2 = nn.Conv3d(in_channels=24, out_channels=128, padding=(0, 0, 0),\n",
        "                               kernel_size=(1, 1, kernel_3d), stride=(1, 1, 1))\n",
        "        self.batch_norm2 = nn.Sequential(\n",
        "            nn.BatchNorm3d(128, eps=0.001, momentum=0.1, affine=True),  # 0.1\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Conv3d(in_channels=1, out_channels=24, padding=(0, 0, 0),\n",
        "                               kernel_size=(3, 3, 128), stride=(1, 1, 1))\n",
        "        self.batch_norm3 = nn.Sequential(\n",
        "            nn.BatchNorm3d(24, eps=0.001, momentum=0.1, affine=True),  # 0.1\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            FastDeconv(in_channels=24, out_channels=24, kernel_size=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.deconv5 = nn.Sequential(\n",
        "            FastDeconv(in_channels=24, out_channels=24, kernel_size=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.deconv6 = nn.Sequential(\n",
        "            FastDeconv(in_channels=24, out_channels=24, kernel_size=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.avg_pooling = nn.AvgPool3d(kernel_size=(5, 5, 1))\n",
        "        self.full_connection = nn.Sequential(  \n",
        "            nn.Linear(48, classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        x1 = self.batch_norm1(self.conv1(X))\n",
        "\n",
        "        x2 = self.res_net1(x1)\n",
        "        x2 = self.res_net2(x2)\n",
        "        x2 = self.batch_norm2(self.conv2(x2))\n",
        "        x2 = x2.permute(0, 4, 2, 3, 1)\n",
        "        x2 = self.batch_norm3(self.conv3(x2))\n",
        "  \n",
        "        x3 = self.res_net3(x2)\n",
        "        x3 = self.res_net4(x3)\n",
        "        \n",
        "        x4 = self.avg_pooling(x3)\n",
        "        x4_flat = x4.view(x4.size(0), -1)\n",
        "        \n",
        "        a,b,c,d,e = x2.size()\n",
        "        x2 = x2.view(a,b*e,c,d)\n",
        "        x2_90 = x2.transpose(2,3)\n",
        "      \n",
        "        \n",
        "        x1_conv = self.conv4(x2)\n",
        "        x2_conv = self.conv5(x1_conv)\n",
        "        x3_conv = self.conv6(x2_conv)\n",
        "\n",
        "\n",
        "        x1_conv_90 = self.deconv4(x2_90)\n",
        "        x2_conv_90 = self.deconv5(x1_conv_90)\n",
        "        x3_conv_90 = self.deconv6(x2_conv_90)\n",
        "\n",
        "        \n",
        "        x3_conv_flat = x3_conv.view(x3_conv.size()[0],-1)\n",
        "        x3_conv_90_flat = x3_conv_90.view(x3_conv_90.size()[0],-1)\n",
        "        \n",
        "  \n",
        "        merge1 = torch.max(x3_conv_flat, x3_conv_90_flat)\n",
        "    \n",
        "        merge = torch.cat((merge1,x4_flat),dim=1)\n",
        "        \n",
        "        return self.full_connection(merge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51L_WdWFh1By"
      },
      "source": [
        "model = SSRN_network(200, 16).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc0a7Rg0QbtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a514a9-50a8-4eb4-fc3f-d434ab4e4df2"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,9,9,200))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1         [-1, 24, 9, 9, 97]             192\n",
            "       BatchNorm3d-2         [-1, 24, 9, 9, 97]              48\n",
            "              ReLU-3         [-1, 24, 9, 9, 97]               0\n",
            "            Conv3d-4         [-1, 24, 9, 9, 97]           4,056\n",
            "              ReLU-5         [-1, 24, 9, 9, 97]               0\n",
            "       BatchNorm3d-6         [-1, 24, 9, 9, 97]              48\n",
            "            Conv3d-7         [-1, 24, 9, 9, 97]           4,056\n",
            "       BatchNorm3d-8         [-1, 24, 9, 9, 97]              48\n",
            "          Residual-9         [-1, 24, 9, 9, 97]               0\n",
            "           Conv3d-10         [-1, 24, 9, 9, 97]           4,056\n",
            "             ReLU-11         [-1, 24, 9, 9, 97]               0\n",
            "      BatchNorm3d-12         [-1, 24, 9, 9, 97]              48\n",
            "           Conv3d-13         [-1, 24, 9, 9, 97]           4,056\n",
            "      BatchNorm3d-14         [-1, 24, 9, 9, 97]              48\n",
            "         Residual-15         [-1, 24, 9, 9, 97]               0\n",
            "           Conv3d-16         [-1, 128, 9, 9, 1]         298,112\n",
            "      BatchNorm3d-17         [-1, 128, 9, 9, 1]             256\n",
            "             ReLU-18         [-1, 128, 9, 9, 1]               0\n",
            "           Conv3d-19          [-1, 24, 7, 7, 1]          27,672\n",
            "      BatchNorm3d-20          [-1, 24, 7, 7, 1]              48\n",
            "             ReLU-21          [-1, 24, 7, 7, 1]               0\n",
            "           Conv3d-22          [-1, 24, 7, 7, 1]           5,208\n",
            "             ReLU-23          [-1, 24, 7, 7, 1]               0\n",
            "      BatchNorm3d-24          [-1, 24, 7, 7, 1]              48\n",
            "           Conv3d-25          [-1, 24, 7, 7, 1]           5,208\n",
            "      BatchNorm3d-26          [-1, 24, 7, 7, 1]              48\n",
            "         Residual-27          [-1, 24, 7, 7, 1]               0\n",
            "           Conv3d-28          [-1, 24, 7, 7, 1]           5,208\n",
            "             ReLU-29          [-1, 24, 7, 7, 1]               0\n",
            "      BatchNorm3d-30          [-1, 24, 7, 7, 1]              48\n",
            "           Conv3d-31          [-1, 24, 7, 7, 1]           5,208\n",
            "      BatchNorm3d-32          [-1, 24, 7, 7, 1]              48\n",
            "         Residual-33          [-1, 24, 7, 7, 1]               0\n",
            "        AvgPool3d-34          [-1, 24, 1, 1, 1]               0\n",
            "           Conv2d-35             [-1, 24, 5, 5]           5,208\n",
            "             ReLU-36             [-1, 24, 5, 5]               0\n",
            "           Conv2d-37             [-1, 24, 3, 3]           5,208\n",
            "             ReLU-38             [-1, 24, 3, 3]               0\n",
            "           Conv2d-39             [-1, 24, 1, 1]           5,208\n",
            "             ReLU-40             [-1, 24, 1, 1]               0\n",
            "       FastDeconv-41             [-1, 24, 5, 5]           5,208\n",
            "             ReLU-42             [-1, 24, 5, 5]               0\n",
            "       FastDeconv-43             [-1, 24, 3, 3]           5,208\n",
            "             ReLU-44             [-1, 24, 3, 3]               0\n",
            "       FastDeconv-45             [-1, 24, 1, 1]           5,208\n",
            "             ReLU-46             [-1, 24, 1, 1]               0\n",
            "           Linear-47                   [-1, 16]             784\n",
            "================================================================\n",
            "Total params: 395,800\n",
            "Trainable params: 395,800\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 21.98\n",
            "Params size (MB): 1.51\n",
            "Estimated Total Size (MB): 23.55\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQyCDASOKzoj"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v55iUbuOVmEO"
      },
      "source": [
        "from IPython import display\n",
        "def train(net, train_iter, valida_iter, loss, optimizer, device, epochs, early_stopping=True,\n",
        "          early_num=20):\n",
        "    loss_list = [100]\n",
        "    early_epoch = 0\n",
        "\n",
        "    net = net.to(device)\n",
        "    print(\"training on \", device)\n",
        "    start = time.time()\n",
        "    train_loss_list = []\n",
        "    valida_loss_list = []\n",
        "    train_acc_list = []\n",
        "    valida_acc_list = []\n",
        "    for epoch in range(epochs):\n",
        "        train_acc_sum, n = 0.0, 0\n",
        "        time_epoch = time.time()\n",
        "        lr_adjust = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 15, eta_min=0.0, last_epoch=-1)\n",
        "        for X, y in train_iter:\n",
        "            \n",
        "            batch_count, train_l_sum = 0, 0\n",
        "            #X = X.permute(0, 3, 1, 2)\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_hat = net(X)\n",
        "            # print('y_hat', y_hat)\n",
        "            # print('y', y)\n",
        "            l = loss(y_hat, y.long())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            train_l_sum += l.cpu().item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
        "            n += y.shape[0]\n",
        "            batch_count += 1\n",
        "        lr_adjust.step(epoch)\n",
        "        valida_acc, valida_loss = evaluate_accuracy(valida_iter, net, loss, device)\n",
        "        loss_list.append(valida_loss)\n",
        "\n",
        "        \n",
        "        train_loss_list.append(train_l_sum) # / batch_count)\n",
        "        train_acc_list.append(train_acc_sum / n)\n",
        "        valida_loss_list.append(valida_loss)\n",
        "        valida_acc_list.append(valida_acc)\n",
        "\n",
        "        print('epoch %d, train loss %.6f, train acc %.3f, valida loss %.6f, valida acc %.3f, time %.1f sec'\n",
        "                % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, valida_loss, valida_acc, time.time() - time_epoch))\n",
        "\n",
        "        PATH = \"./net_DBA.pt\"\n",
        "        # if loss_list[-1] <= 0.01 and valida_acc >= 0.95:\n",
        "        #     torch.save(net.state_dict(), PATH)\n",
        "        #     break\n",
        "\n",
        "        if early_stopping and loss_list[-2] < loss_list[-1]:  # < 0.05) and (loss_list[-1] <= 0.05):\n",
        "            if early_epoch == 0: # and valida_acc > 0.9:\n",
        "                torch.save(net.state_dict(), PATH)\n",
        "            early_epoch += 1\n",
        "            loss_list[-1] = loss_list[-2]\n",
        "            if early_epoch == early_num:\n",
        "                net.load_state_dict(torch.load(PATH))\n",
        "                break\n",
        "        else:\n",
        "            early_epoch = 0\n",
        "\n",
        "    \n",
        "    set_figsize()\n",
        "    plt.figure(figsize=(8, 8.5))\n",
        "    train_accuracy =   plt.subplot(221)\n",
        "    train_accuracy.set_title('train_accuracy')\n",
        "    plt.plot(np.linspace(1, epoch, len(train_acc_list)), train_acc_list, color='green')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('train_accuracy')\n",
        "    \n",
        "    test_accuracy =   plt.subplot(222)\n",
        "    test_accuracy.set_title('valida_accuracy')\n",
        "    plt.plot(np.linspace(1, epoch, len(valida_acc_list)), valida_acc_list, color='deepskyblue')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('test_accuracy')\n",
        "\n",
        "    loss_sum =   plt.subplot(223)\n",
        "    loss_sum.set_title('train_loss')\n",
        "    plt.plot(np.linspace(1, epoch, len(train_loss_list)), train_loss_list, color='red')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('train loss')\n",
        "    # ls_plot = np.array(ls_plot)\n",
        "\n",
        "    test_loss =   plt.subplot(224)\n",
        "    test_loss.set_title('valida_loss')\n",
        "    plt.plot(np.linspace(1, epoch, len(valida_loss_list)), valida_loss_list, color='gold')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('valida loss')\n",
        "    # ls_plot = np.array(ls_plot)\n",
        "\n",
        "    plt.show()\n",
        "    print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec'\n",
        "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, time.time() - start))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAHq14_5TCgA"
      },
      "source": [
        "def sampling(proportion, ground_truth):\n",
        "    train = {}\n",
        "    test = {}\n",
        "    labels_loc = {}\n",
        "    m = max(ground_truth)\n",
        "    for i in range(m):\n",
        "        indexes = [j for j, x in enumerate(ground_truth.ravel().tolist()) if x == i + 1]\n",
        "        np.random.shuffle(indexes)\n",
        "        labels_loc[i] = indexes\n",
        "        if proportion != 1:\n",
        "            nb_val = max(int((1 - proportion) * len(indexes)), 3)\n",
        "        else:\n",
        "            nb_val = 0\n",
        "        train[i] = indexes[:nb_val]\n",
        "        test[i] = indexes[nb_val:]\n",
        "    train_indexes = []\n",
        "    test_indexes = []\n",
        "    for i in range(m):\n",
        "        train_indexes += train[i]\n",
        "        test_indexes += test[i]\n",
        "    np.random.shuffle(train_indexes)\n",
        "    np.random.shuffle(test_indexes)\n",
        "    return train_indexes, test_indexes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W98D-S4f3Gh"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba8FyYpCMhGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855f10f1-a627-49af-bc74-7fe03947bb34"
      },
      "source": [
        "!pip install torch-optimizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-optimizer in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from torch-optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torch-optimizer) (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch-optimizer) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch-optimizer) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch-optimizer) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->torch-optimizer) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npT7LkWtMp-1"
      },
      "source": [
        "import torch_optimizer as optim2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPV8ZlZqOPRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f59ae2-9f22-489f-8be7-19742f257bf7"
      },
      "source": [
        "import time\n",
        "import collections\n",
        "from torch import optim\n",
        "for index_iter in range(ITER):\n",
        "    print('iter:', index_iter)\n",
        "    #define the model\n",
        "    #net = pResNet(32, 48, CLASSES_NUM, BAND, 2, 16, bottleneck=True)\n",
        "    #net = resnet20(num_classes=CLASSES_NUM)\n",
        "    net = SSRN_network(BAND, CLASSES_NUM)\n",
        "\n",
        "    #optimizer = optim2.DiffGrad(net.parameters(), lr=lr, amsgrad=False) #, weight_decay=0.0001)\n",
        "    optimizer = optim2.DiffGrad(net.parameters(), lr= 1e-3, betas=(0.9, 0.999),\n",
        "    eps=1e-8,\n",
        "    weight_decay=0)\n",
        "    time_1 = int(time.time())\n",
        "    np.random.seed(seeds[index_iter])\n",
        "    train_indices, test_indices = sampling(VALIDATION_SPLIT, gt)\n",
        "    _, total_indices = sampling(1, gt)\n",
        "\n",
        "    TRAIN_SIZE = len(train_indices)\n",
        "    print('Train size: ', TRAIN_SIZE)\n",
        "    TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
        "    print('Test size: ', TEST_SIZE)\n",
        "    VAL_SIZE = int(TRAIN_SIZE)\n",
        "    print('Validation size: ', VAL_SIZE)\n",
        "\n",
        "    print('-----Selecting Small Pieces from the Original Cube Data-----')\n",
        "    train_iter, valida_iter, test_iter, all_iter = generate_iter(TRAIN_SIZE, train_indices, TEST_SIZE, test_indices, TOTAL_SIZE, total_indices, VAL_SIZE,whole_data, PATCH_LENGTH, padded_data, INPUT_DIMENSION, 16, gt) #batchsize in 1\n",
        "\n",
        "    tic1 = time.clock()\n",
        "    train(net, train_iter, valida_iter, loss, optimizer, device, epochs=100)\n",
        "    toc1 = time.clock()\n",
        "\n",
        "    pred_test = []\n",
        "    tic2 = time.clock()\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_iter:\n",
        "            #X = X.permute(0, 3, 1, 2)\n",
        "            X = X.to(device)\n",
        "            net.eval()  \n",
        "            y_hat = net(X)\n",
        "            pred_test.extend(np.array(net(X).cpu().argmax(axis=1)))\n",
        "    toc2 = time.clock()\n",
        "    collections.Counter(pred_test)\n",
        "    gt_test = gt[test_indices] - 1\n",
        "\n",
        "\n",
        "    overall_acc = metrics.accuracy_score(pred_test, gt_test[:-VAL_SIZE])\n",
        "    confusion_matrix = metrics.confusion_matrix(pred_test, gt_test[:-VAL_SIZE])\n",
        "    each_acc, average_acc = aa_and_each_accuracy(confusion_matrix)\n",
        "    kappa = metrics.cohen_kappa_score(pred_test, gt_test[:-VAL_SIZE])\n",
        "\n",
        "    torch.save(net.state_dict(), \"/content/\" + str(round(overall_acc, 3)) + '.pt')\n",
        "    KAPPA.append(kappa)\n",
        "    OA.append(overall_acc)\n",
        "    AA.append(average_acc)\n",
        "    TRAINING_TIME.append(toc1 - tic1)\n",
        "    TESTING_TIME.append(toc2 - tic2)\n",
        "    ELEMENT_ACC[index_iter, :] = each_acc\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter: 0\n",
            "Train size:  1018\n",
            "Test size:  9231\n",
            "Validation size:  1018\n",
            "-----Selecting Small Pieces from the Original Cube Data-----\n",
            "(1018, 9, 9, 200)\n",
            "training on  cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning:\n",
            "\n",
            "The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, train loss 1.026750, train acc 0.491, valida loss 1.327319, valida acc 0.548, time 20.5 sec\n",
            "epoch 2, train loss 1.096629, train acc 0.648, valida loss 0.862475, valida acc 0.727, time 20.5 sec\n",
            "epoch 3, train loss 0.621585, train acc 0.752, valida loss 0.996730, valida acc 0.787, time 20.6 sec\n",
            "epoch 4, train loss 0.573272, train acc 0.839, valida loss 0.363658, valida acc 0.865, time 20.5 sec\n",
            "epoch 5, train loss 0.152308, train acc 0.876, valida loss 0.689947, valida acc 0.910, time 20.5 sec\n",
            "epoch 6, train loss 0.226787, train acc 0.929, valida loss 0.779961, valida acc 0.872, time 20.5 sec\n",
            "epoch 7, train loss 0.022086, train acc 0.933, valida loss 0.194769, valida acc 0.908, time 20.6 sec\n",
            "epoch 8, train loss 0.437689, train acc 0.943, valida loss 0.186793, valida acc 0.898, time 20.5 sec\n",
            "epoch 9, train loss 0.242283, train acc 0.916, valida loss 0.260132, valida acc 0.950, time 20.5 sec\n",
            "epoch 10, train loss 0.048545, train acc 0.966, valida loss 0.457843, valida acc 0.959, time 20.4 sec\n",
            "epoch 11, train loss 0.096804, train acc 0.966, valida loss 0.197146, valida acc 0.950, time 20.5 sec\n",
            "epoch 12, train loss 0.047046, train acc 0.972, valida loss 0.054597, valida acc 0.939, time 20.5 sec\n",
            "epoch 13, train loss 0.104718, train acc 0.986, valida loss 0.149785, valida acc 0.944, time 20.5 sec\n",
            "epoch 14, train loss 0.037798, train acc 0.948, valida loss 0.013300, valida acc 0.924, time 20.5 sec\n",
            "epoch 15, train loss 0.142359, train acc 0.951, valida loss 0.047425, valida acc 0.961, time 20.6 sec\n",
            "epoch 17, train loss 0.035410, train acc 0.974, valida loss 0.048373, valida acc 0.945, time 20.5 sec\n",
            "epoch 18, train loss 0.054381, train acc 0.979, valida loss 0.000857, valida acc 0.972, time 20.5 sec\n",
            "epoch 19, train loss 0.044125, train acc 0.987, valida loss 0.177863, valida acc 0.960, time 20.5 sec\n",
            "epoch 20, train loss 0.008212, train acc 0.989, valida loss 0.028647, valida acc 0.943, time 20.5 sec\n",
            "epoch 21, train loss 0.005866, train acc 0.994, valida loss 0.011764, valida acc 0.972, time 20.4 sec\n",
            "epoch 22, train loss 0.022539, train acc 0.989, valida loss 0.810487, valida acc 0.969, time 20.5 sec\n",
            "epoch 23, train loss 0.009189, train acc 0.992, valida loss 0.001617, valida acc 0.985, time 20.4 sec\n",
            "epoch 24, train loss 0.000583, train acc 0.992, valida loss 0.003471, valida acc 0.970, time 20.5 sec\n",
            "epoch 25, train loss 0.012893, train acc 0.986, valida loss 0.019006, valida acc 0.961, time 20.5 sec\n",
            "epoch 26, train loss 0.000935, train acc 0.987, valida loss 0.156170, valida acc 0.969, time 20.6 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJFBXw38KrVt"
      },
      "source": [
        "# Map, Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LKalsj4SEq8"
      },
      "source": [
        "print(\"--------\" + \" Training Finished-----------\")\n",
        "record_output(OA, AA, KAPPA, ELEMENT_ACC, TRAINING_TIME, TESTING_TIME,confusion_matrix,\n",
        "                     '/content/'  + str(img_rows) + '_' + Dataset + 'split：' + str(VALIDATION_SPLIT) + 'lr：' + str(lr) + '.txt')\n",
        "\n",
        "\n",
        "generate_png(all_iter, net, gt_hsi, Dataset, device, total_indices)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}